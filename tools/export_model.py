import argparse
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer

from spatiallm import Layout  # noqa


def parse_args():
    parser = argparse.ArgumentParser(description="å¯¼å‡º SpatialLM æ¨¡å‹")
    parser.add_argument(
        "--src",
        type=str,
        default="saves/spatiallm-qwen-0.5b-sft/checkpoint-16050",
        help="æºæ¨¡å‹è·¯å¾„ (é»˜è®¤: saves/spatiallm-qwen-0.5b-sft/checkpoint-16050)"
    )
    parser.add_argument(
        "--dst",
        type=str,
        default="exports/spatiallm-qwen-0.5b-sft-fp32",
        help="ç›®æ ‡å¯¼å‡ºè·¯å¾„ (é»˜è®¤: exports/spatiallm-qwen-0.5b-sft-fp32)"
    )
    parser.add_argument(
        "--dtype",
        type=str,
        choices=["float32", "float16", "bfloat16"],
        default="float32",
        help="æ¨¡å‹æ•°æ®ç±»å‹ (é»˜è®¤: float32)"
    )
    parser.add_argument(
        "--device",
        type=str,
        default="cuda",
        help="è¿è¡Œè®¾å¤‡ (é»˜è®¤: cuda)"
    )
    parser.add_argument(
        "--no-safe-serialization",
        action="store_true",
        help="ä¸ä½¿ç”¨å®‰å…¨åºåˆ—åŒ– (.safetensors)"
    )
    
    return parser.parse_args()


def main():
    args = parse_args()
    
    # è®¾ç½®æ•°æ®ç±»å‹
    dtype_map = {
        "float32": torch.float32,
        "float16": torch.float16,
        "bfloat16": torch.bfloat16
    }
    torch_dtype = dtype_map[args.dtype]
    
    print(f"ğŸ“‚ æºæ¨¡å‹è·¯å¾„: {args.src}")
    print(f"ğŸ“ ç›®æ ‡è·¯å¾„: {args.dst}")
    print(f"ğŸ”¢ æ•°æ®ç±»å‹: {args.dtype}")
    print(f"ğŸ’» è®¾å¤‡: {args.device}")
    
    # åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨
    print("ğŸ”„ åŠ è½½åˆ†è¯å™¨...")
    tokenizer = AutoTokenizer.from_pretrained(args.src)
    
    print("ğŸ”„ åŠ è½½æ¨¡å‹...")
    model = AutoModelForCausalLM.from_pretrained(args.src, torch_dtype=torch_dtype)
    model.to(args.device)
    model.set_point_backbone_dtype(torch_dtype)
    
    # ä¿å­˜æ¨¡å‹
    print("ğŸ’¾ ä¿å­˜æ¨¡å‹...")
    safe_serialization = not args.no_safe_serialization
    model.save_pretrained(args.dst, safe_serialization=safe_serialization)
    tokenizer.save_pretrained(args.dst)
    
    serialization_type = ".safetensors" if safe_serialization else ".bin"
    print(f"âœ… æ¨¡å‹å·²å¯¼å‡ºåˆ°: {args.dst} (æ ¼å¼: {serialization_type})")


if __name__ == "__main__":
    main()
